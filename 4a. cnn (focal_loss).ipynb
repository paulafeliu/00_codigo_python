{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:02<00:00, 120.81it/s]\n",
      "5000it [00:02, 2441.88it/s]\n",
      "5000it [00:02, 2417.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha * focal_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "root_dir = r'/Users/roy/Downloads/archive/'  # Ruta del directorio de imágenes\n",
    "\n",
    "N_IDC = []\n",
    "P_IDC = []\n",
    "\n",
    "for dir_name in tqdm(os.listdir(root_dir)):\n",
    "    dir_path = os.path.join(root_dir, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        negative_dir_path = os.path.join(dir_path, '0')\n",
    "        positive_dir_path = os.path.join(dir_path, '1')\n",
    "        if os.path.isdir(negative_dir_path) and os.path.isdir(positive_dir_path):\n",
    "            negative_image_paths = [\n",
    "                os.path.join(negative_dir_path, image_name)\n",
    "                for image_name in os.listdir(negative_dir_path)\n",
    "                if image_name.endswith('.png')\n",
    "            ]\n",
    "            positive_image_paths = [\n",
    "                os.path.join(positive_dir_path, image_name)\n",
    "                for image_name in os.listdir(positive_dir_path)\n",
    "                if image_name.endswith('.png')\n",
    "            ]\n",
    "            N_IDC.extend(negative_image_paths)\n",
    "            P_IDC.extend(positive_image_paths)\n",
    "\n",
    "total_images = 5000  # Cambiado a 5000 para equilibrar las clases (2500 benignos y 2500 malignos)\n",
    "\n",
    "n_img_arr = np.zeros(shape=(total_images, 50, 50, 3), dtype=np.float32)\n",
    "p_img_arr = np.zeros(shape=(total_images, 50, 50, 3), dtype=np.float32)\n",
    "label_n = np.zeros(total_images)\n",
    "label_p = np.ones(total_images)\n",
    "\n",
    "for i, img in tqdm(enumerate(N_IDC[:total_images])):\n",
    "    n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    n_img_size = cv2.resize(n_img, (50, 50), interpolation=cv2.INTER_LINEAR)\n",
    "    n_img_arr[i] = n_img_size\n",
    "\n",
    "for i, img in tqdm(enumerate(P_IDC[:total_images])):\n",
    "    p_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    p_img_size = cv2.resize(p_img, (50, 50), interpolation=cv2.INTER_LINEAR)\n",
    "    p_img_arr[i] = p_img_size\n",
    "\n",
    "X = np.concatenate((p_img_arr, n_img_arr), axis=0)\n",
    "y = np.concatenate((label_p, label_n), axis=0)\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_size=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(64, 24)\n",
    "        self.fc4 = nn.Linear(24, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=None)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100.0 * correct / len(val_loader.dataset)\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Train Loss: 0.0913, Val Loss: 0.1486, Val Accuracy: 81.28%\n",
      "Epoch: 01, Train Loss: 0.0740, Val Loss: 0.1635, Val Accuracy: 69.17%\n",
      "Epoch: 02, Train Loss: 0.0746, Val Loss: 0.0891, Val Accuracy: 86.17%\n",
      "Epoch: 03, Train Loss: 0.0636, Val Loss: 0.0630, Val Accuracy: 90.22%\n",
      "Epoch: 04, Train Loss: 0.0670, Val Loss: 0.6854, Val Accuracy: 62.39%\n",
      "Epoch: 05, Train Loss: 0.0645, Val Loss: 0.0781, Val Accuracy: 86.78%\n",
      "Epoch: 06, Train Loss: 0.0591, Val Loss: 0.4326, Val Accuracy: 50.33%\n",
      "Epoch: 07, Train Loss: 0.0584, Val Loss: 0.0691, Val Accuracy: 87.72%\n",
      "Epoch: 08, Train Loss: 0.0514, Val Loss: 0.4015, Val Accuracy: 64.94%\n",
      "Epoch: 09, Train Loss: 0.0499, Val Loss: 0.0593, Val Accuracy: 90.72%\n",
      "Epoch: 10, Train Loss: 0.0475, Val Loss: 0.1264, Val Accuracy: 81.06%\n",
      "Epoch: 11, Train Loss: 0.0486, Val Loss: 0.1976, Val Accuracy: 76.06%\n",
      "Epoch: 12, Train Loss: 0.0446, Val Loss: 0.2016, Val Accuracy: 77.44%\n",
      "Epoch: 13, Train Loss: 0.0458, Val Loss: 1.3397, Val Accuracy: 65.78%\n",
      "Epoch: 14, Train Loss: 0.0482, Val Loss: 0.1245, Val Accuracy: 83.67%\n",
      "Epoch: 15, Train Loss: 0.0401, Val Loss: 0.0441, Val Accuracy: 93.89%\n",
      "Epoch: 16, Train Loss: 0.0400, Val Loss: 0.0448, Val Accuracy: 93.17%\n",
      "Epoch: 17, Train Loss: 0.0390, Val Loss: 0.6140, Val Accuracy: 66.50%\n",
      "Epoch: 18, Train Loss: 0.0380, Val Loss: 0.3373, Val Accuracy: 58.83%\n",
      "Epoch: 19, Train Loss: 0.0384, Val Loss: 0.0530, Val Accuracy: 92.89%\n",
      "Epoch: 20, Train Loss: 0.0337, Val Loss: 0.0838, Val Accuracy: 89.17%\n",
      "Epoch: 21, Train Loss: 0.0311, Val Loss: 0.2207, Val Accuracy: 72.50%\n",
      "Epoch: 22, Train Loss: 0.0279, Val Loss: 0.1713, Val Accuracy: 76.22%\n",
      "Epoch: 23, Train Loss: 0.0280, Val Loss: 0.1176, Val Accuracy: 88.94%\n",
      "Epoch: 24, Train Loss: 0.0252, Val Loss: 0.0877, Val Accuracy: 88.94%\n",
      "Epoch: 25, Train Loss: 0.0230, Val Loss: 0.0721, Val Accuracy: 91.89%\n",
      "Epoch: 26, Train Loss: 0.0275, Val Loss: 0.1047, Val Accuracy: 84.67%\n",
      "Epoch: 27, Train Loss: 0.0229, Val Loss: 0.0892, Val Accuracy: 89.17%\n",
      "Epoch: 28, Train Loss: 0.0219, Val Loss: 0.0950, Val Accuracy: 88.72%\n",
      "Epoch: 29, Train Loss: 0.0204, Val Loss: 0.2640, Val Accuracy: 82.67%\n",
      "Epoch: 30, Train Loss: 0.0209, Val Loss: 0.1132, Val Accuracy: 89.33%\n",
      "Epoch: 31, Train Loss: 0.0175, Val Loss: 0.0749, Val Accuracy: 92.39%\n",
      "Epoch: 32, Train Loss: 0.0196, Val Loss: 0.1183, Val Accuracy: 85.50%\n",
      "Epoch: 33, Train Loss: 0.0226, Val Loss: 0.0819, Val Accuracy: 90.94%\n",
      "Epoch: 34, Train Loss: 0.0205, Val Loss: 0.1549, Val Accuracy: 83.39%\n",
      "Epoch: 35, Train Loss: 0.0153, Val Loss: 0.1863, Val Accuracy: 85.89%\n",
      "Epoch: 36, Train Loss: 0.0151, Val Loss: 0.1524, Val Accuracy: 84.94%\n",
      "Epoch: 37, Train Loss: 0.0130, Val Loss: 0.0944, Val Accuracy: 91.94%\n",
      "Epoch: 38, Train Loss: 0.0124, Val Loss: 0.0868, Val Accuracy: 93.06%\n",
      "Epoch: 39, Train Loss: 0.0157, Val Loss: 0.0810, Val Accuracy: 92.44%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32  # Define the batch size\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float().permute(0, 3, 1, 2), torch.from_numpy(y_train).long())\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val).float().permute(0, 3, 1, 2), torch.from_numpy(y_val).long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 40\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    model.eval()\n",
    "    val_loss, val_accuracy = evaluate(model, device, val_loader, criterion)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    print('Epoch: {:02d}, Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.2f}%'.format(\n",
    "        epoch, train_loss, val_loss, val_accuracy))\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(train_loss, val_loss):\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss, label='Train Loss')\n",
    "    plt.plot(epochs, val_loss, label='Val Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e1928ad34685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-164b11eed889>\u001b[0m in \u001b[0;36mplot_losses\u001b[0;34m(loss1, loss2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming both loss lists have the same length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "plot_losses(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
