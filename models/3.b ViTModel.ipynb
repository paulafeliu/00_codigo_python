{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.15.0)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (6.0)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (2.0.0)\n",
      "Requirement already satisfied: filelock in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (4.5.0)\n",
      "Requirement already satisfied: sympy in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (2023.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (23.0)\n",
      "Requirement already satisfied: requests in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (4.65.0)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from sympy->torch>=1.7->timm) (1.2.1)\n",
      "Installing collected packages: safetensors, huggingface-hub, timm\n",
      "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /anaconda/envs/pytorch/lib/python3.9/site-packages (0.9.2)\n",
      "Requirement already satisfied: safetensors in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.3.1)\n",
      "Requirement already satisfied: pyyaml in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: torchvision in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.15.0)\n",
      "Requirement already satisfied: huggingface-hub in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: torch>=1.7 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from timm) (2.0.0)\n",
      "Requirement already satisfied: filelock in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (4.5.0)\n",
      "Requirement already satisfied: sympy in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (2023.4.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (4.65.0)\n",
      "Requirement already satisfied: requests in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (2.29.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from huggingface-hub->timm) (23.0)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /anaconda/envs/pytorch/lib/python3.9/site-packages (from sympy->torch>=1.7->timm) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import math\n",
    "from torchvision.models import vision_transformer\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model('vit_small_patch16_224', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 2)  # Cambiar la capa de clasificación para tener 2 clases (tumores benignos y malignos)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta principal\n",
    "main_folder = '/home/xnmaster/dataset/'\n",
    "\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Just normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size para el entrenamiento (cambia según la cantidad de memoria disponible)\n",
    "batch_size = 8\n",
    "\n",
    "# Crear datasets de entrenamiento y validación\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(main_folder, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "\n",
    "# Generar los índices para el subconjunto\n",
    "subset_indices_train = torch.randperm(len(image_datasets['train']))[:int(0.03*len(image_datasets['train']))]\n",
    "subset_indices_val = torch.randperm(len(image_datasets['val']))[:int(0.03*len(image_datasets['val']))]\n",
    "\n",
    "# Crear subconjuntos\n",
    "train_data_subset = Subset(image_datasets['train'], subset_indices_train)\n",
    "val_data_subset = Subset(image_datasets['val'], subset_indices_val)\n",
    "\n",
    "\n",
    "# Crear dataloaders de entrenamiento y validación\n",
    "dataloaders_dict = {\n",
    "    'train': DataLoader(train_data_subset, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_data_subset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "}\n",
    "\n",
    "#dataloaders_dict = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val','test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento del modelo\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    acc_history = {\"train\": [], \"val\": []}\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_model_wts = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            acc_history[phase].append(epoch_acc)\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, acc_history, losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.4714 Acc: 0.7916\n",
      "val Loss: 0.3775 Acc: 0.8255\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.3918 Acc: 0.8254\n",
      "val Loss: 0.4079 Acc: 0.8038\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.3801 Acc: 0.8372\n",
      "val Loss: 0.4869 Acc: 0.7927\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.3827 Acc: 0.8338\n",
      "val Loss: 0.4683 Acc: 0.7750\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.3820 Acc: 0.8320\n",
      "val Loss: 0.3677 Acc: 0.8366\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.3716 Acc: 0.8376\n",
      "val Loss: 0.3485 Acc: 0.8522\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, acc_history, losses \u001b[39m=\u001b[39m train_model(model, dataloaders_dict, criterion, optimizer, num_epochs)\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     37\u001b[0m             optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 39\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m     running_corrects \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(preds \u001b[39m==\u001b[39m labels\u001b[39m.\u001b[39mdata)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     42\u001b[0m epoch_loss \u001b[39m=\u001b[39m running_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloaders[phase]\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, acc_history, losses = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses and accuracies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.plot(losses[\"train\"], label=\"training loss\")\n",
    "ax1.plot(losses[\"val\"], label=\"validation loss\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(acc_history[\"train\"],label=\"training accuracy\")\n",
    "ax2.plot(acc_history[\"val\"],label=\"val accuracy\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indices_test = torch.randperm(len(image_datasets['test']))[:int(0.3*len(image_datasets['test']))]\n",
    "test_data_subset = torch.utils.data.Subset(image_datasets['test'], subset_indices_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data_subset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_accuracy = evaluate_model(model, dataloaders_dict['test'], criterion)\n",
    "\n",
    "print('Test Loss: {:.4f}, Test Accuracy: {:.4f}'.format(test_loss, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
