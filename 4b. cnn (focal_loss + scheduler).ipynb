{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha * focal_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "root_dir = r'C:\\Users\\User\\Desktop\\UAB\\2nd year\\2nd semester\\neural network-deep learning\\project'  # Ruta del directorio de im√°genes\n",
    "\n",
    "N_IDC = []\n",
    "P_IDC = []\n",
    "\n",
    "for dir_name in tqdm(os.listdir(root_dir)):\n",
    "    dir_path = os.path.join(root_dir, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        negative_dir_path = os.path.join(dir_path, '0')\n",
    "        positive_dir_path = os.path.join(dir_path, '1')\n",
    "        if os.path.isdir(negative_dir_path) and os.path.isdir(positive_dir_path):\n",
    "            negative_image_paths = [\n",
    "                os.path.join(negative_dir_path, image_name)\n",
    "                for image_name in os.listdir(negative_dir_path)\n",
    "                if image_name.endswith('.png')\n",
    "            ]\n",
    "            positive_image_paths = [\n",
    "                os.path.join(positive_dir_path, image_name)\n",
    "                for image_name in os.listdir(positive_dir_path)\n",
    "                if image_name.endswith('.png')\n",
    "            ]\n",
    "            N_IDC.extend(negative_image_paths)\n",
    "            P_IDC.extend(positive_image_paths)\n",
    "\n",
    "total_images = 10000  # Cambiado a 5000 para equilibrar las clases (2500 benignos y 2500 malignos)\n",
    "\n",
    "n_img_arr = np.zeros(shape=(total_images, 50, 50, 3), dtype=np.float32)\n",
    "p_img_arr = np.zeros(shape=(total_images, 50, 50, 3), dtype=np.float32)\n",
    "label_n = np.zeros(total_images)\n",
    "label_p = np.ones(total_images)\n",
    "\n",
    "for i, img in tqdm(enumerate(N_IDC[:total_images])):\n",
    "    n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    n_img_size = cv2.resize(n_img, (50, 50), interpolation=cv2.INTER_LINEAR)\n",
    "    n_img_arr[i] = n_img_size\n",
    "\n",
    "for i, img in tqdm(enumerate(P_IDC[:total_images])):\n",
    "    p_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    p_img_size = cv2.resize(p_img, (50, 50), interpolation=cv2.INTER_LINEAR)\n",
    "    p_img_arr[i] = p_img_size\n",
    "\n",
    "X = np.concatenate((p_img_arr, n_img_arr), axis=0)\n",
    "y = np.concatenate((label_p, label_n), axis=0)\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_size=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(64, 24)\n",
    "        self.fc4 = nn.Linear(24, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha=None) #provar valors de gamma (1, 2, 3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100.0 * correct / len(val_loader.dataset)\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Define the batch size\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float().permute(0, 3, 1, 2), torch.from_numpy(y_train).long())\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val).float().permute(0, 3, 1, 2), torch.from_numpy(y_val).long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 40\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    model.eval()\n",
    "    val_loss, val_accuracy = evaluate(model, device, val_loader, criterion)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    print('Epoch: {:02d}, Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.2f}%, Learning Rate: {:.6f}'.format(\n",
    "        epoch, train_loss, val_loss, val_accuracy, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
