{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 286/286 [00:09<00:00, 30.45it/s]\n",
      "5000it [00:04, 1079.04it/s]\n",
      "5000it [00:04, 1175.38it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_dir = r'C:\\Users\\User\\Desktop\\UAB\\2nd year\\2nd semester\\neural network-deep learning\\project'  # Ruta del directorio de imágenes\n",
    "\n",
    "N_IDC = []\n",
    "P_IDC = []\n",
    "\n",
    "for dir_name in tqdm(os.listdir(root_dir)):\n",
    "    dir_path = os.path.join(root_dir, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        negative_dir_path = os.path.join(dir_path, '0')\n",
    "        positive_dir_path = os.path.join(dir_path, '1')\n",
    "        if os.path.isdir(negative_dir_path) and os.path.isdir(positive_dir_path):\n",
    "            negative_image_paths = [\n",
    "                os.path.join(negative_dir_path, image_name)\n",
    "                for image_name in os.listdir(negative_dir_path)\n",
    "                if image_name.endswith('.png')\n",
    "            ]\n",
    "            positive_image_paths = [\n",
    "                os.path.join(positive_dir_path, image_name)\n",
    "                for image_name in os.listdir(positive_dir_path)\n",
    "                if image_name.endswith('.png')\n",
    "            ]\n",
    "            N_IDC.extend(negative_image_paths)\n",
    "            P_IDC.extend(positive_image_paths)\n",
    "\n",
    "total_images = 5000  # Cambiado a 5000 para equilibrar las clases (2500 benignos y 2500 malignos)\n",
    "\n",
    "n_img_arr = np.zeros(shape=(total_images, 50, 50, 3), dtype=np.float32)\n",
    "p_img_arr = np.zeros(shape=(total_images, 50, 50, 3), dtype=np.float32)\n",
    "label_n = np.zeros(total_images)\n",
    "label_p = np.ones(total_images)\n",
    "\n",
    "for i, img in tqdm(enumerate(N_IDC[:total_images])):\n",
    "    n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    n_img_size = cv2.resize(n_img, (50, 50), interpolation=cv2.INTER_LINEAR)\n",
    "    n_img_arr[i] = n_img_size\n",
    "\n",
    "for i, img in tqdm(enumerate(P_IDC[:total_images])):\n",
    "    p_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    p_img_size = cv2.resize(p_img, (50, 50), interpolation=cv2.INTER_LINEAR)\n",
    "    p_img_arr[i] = p_img_size\n",
    "\n",
    "X = np.concatenate((p_img_arr, n_img_arr), axis=0)\n",
    "y = np.concatenate((label_p, label_n), axis=0)\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "# probar --> y = to_categorical(y)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, output_size=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.3)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fc3 = nn.Linear(64, 24)\n",
    "        self.fc4 = nn.Linear(24, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# probar --> criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# probar --> optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    return train_loss\n",
    "\n",
    "def evaluate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100.0 * correct / len(val_loader.dataset)\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Train Loss: 0.4720, Val Loss: 0.5599, Val Accuracy: 74.94%\n",
      "Epoch: 01, Train Loss: 0.4474, Val Loss: 0.5734, Val Accuracy: 72.00%\n",
      "Epoch: 02, Train Loss: 0.4452, Val Loss: 0.5256, Val Accuracy: 78.44%\n",
      "Epoch: 03, Train Loss: 0.4415, Val Loss: 0.4557, Val Accuracy: 85.06%\n",
      "Epoch: 04, Train Loss: 0.4398, Val Loss: 0.4449, Val Accuracy: 86.22%\n",
      "Epoch: 05, Train Loss: 0.4395, Val Loss: 0.7441, Val Accuracy: 56.28%\n",
      "Epoch: 06, Train Loss: 0.4354, Val Loss: 0.4519, Val Accuracy: 85.78%\n",
      "Epoch: 07, Train Loss: 0.4396, Val Loss: 0.4336, Val Accuracy: 87.44%\n",
      "Epoch: 08, Train Loss: 0.4315, Val Loss: 0.4643, Val Accuracy: 83.94%\n",
      "Epoch: 09, Train Loss: 0.4355, Val Loss: 0.4532, Val Accuracy: 85.72%\n",
      "Epoch: 10, Train Loss: 0.4325, Val Loss: 0.4635, Val Accuracy: 83.89%\n",
      "Epoch: 11, Train Loss: 0.4286, Val Loss: 0.4714, Val Accuracy: 82.72%\n",
      "Epoch: 12, Train Loss: 0.4257, Val Loss: 0.7406, Val Accuracy: 57.22%\n",
      "Epoch: 13, Train Loss: 0.4263, Val Loss: 0.4561, Val Accuracy: 85.28%\n",
      "Epoch: 14, Train Loss: 0.4264, Val Loss: 0.4496, Val Accuracy: 85.56%\n",
      "Epoch: 15, Train Loss: 0.4245, Val Loss: 0.4671, Val Accuracy: 83.61%\n",
      "Epoch: 16, Train Loss: 0.4264, Val Loss: 0.4804, Val Accuracy: 83.17%\n",
      "Epoch: 17, Train Loss: 0.4221, Val Loss: 0.4563, Val Accuracy: 85.33%\n",
      "Epoch: 18, Train Loss: 0.4216, Val Loss: 0.4368, Val Accuracy: 86.67%\n",
      "Epoch: 19, Train Loss: 0.4192, Val Loss: 0.5185, Val Accuracy: 78.56%\n",
      "Epoch: 20, Train Loss: 0.4176, Val Loss: 0.4365, Val Accuracy: 87.44%\n",
      "Epoch: 21, Train Loss: 0.4176, Val Loss: 0.4369, Val Accuracy: 87.39%\n",
      "Epoch: 22, Train Loss: 0.4118, Val Loss: 0.4402, Val Accuracy: 86.50%\n",
      "Epoch: 23, Train Loss: 0.4100, Val Loss: 0.4304, Val Accuracy: 88.06%\n",
      "Epoch: 24, Train Loss: 0.4086, Val Loss: 0.4709, Val Accuracy: 83.67%\n",
      "Epoch: 25, Train Loss: 0.4070, Val Loss: 0.5227, Val Accuracy: 78.50%\n",
      "Epoch: 26, Train Loss: 0.4040, Val Loss: 0.4430, Val Accuracy: 86.78%\n",
      "Epoch: 27, Train Loss: 0.4026, Val Loss: 0.4889, Val Accuracy: 81.50%\n",
      "Epoch: 28, Train Loss: 0.4002, Val Loss: 0.4610, Val Accuracy: 84.72%\n",
      "Epoch: 29, Train Loss: 0.4075, Val Loss: 0.4550, Val Accuracy: 85.50%\n",
      "Epoch: 30, Train Loss: 0.4022, Val Loss: 0.4369, Val Accuracy: 87.17%\n",
      "Epoch: 31, Train Loss: 0.3935, Val Loss: 0.4419, Val Accuracy: 86.83%\n",
      "Epoch: 32, Train Loss: 0.3958, Val Loss: 0.4584, Val Accuracy: 85.22%\n",
      "Epoch: 33, Train Loss: 0.3849, Val Loss: 0.4590, Val Accuracy: 85.11%\n",
      "Epoch: 34, Train Loss: 0.3892, Val Loss: 0.4564, Val Accuracy: 85.39%\n",
      "Epoch: 35, Train Loss: 0.3876, Val Loss: 0.4736, Val Accuracy: 83.50%\n",
      "Epoch: 36, Train Loss: 0.3839, Val Loss: 0.4588, Val Accuracy: 84.83%\n",
      "Epoch: 37, Train Loss: 0.3848, Val Loss: 0.4416, Val Accuracy: 86.61%\n",
      "Epoch: 38, Train Loss: 0.3835, Val Loss: 0.4713, Val Accuracy: 83.50%\n",
      "Epoch: 39, Train Loss: 0.3829, Val Loss: 0.4689, Val Accuracy: 83.44%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size = 32  # Define the batch size\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float().permute(0, 3, 1, 2), torch.from_numpy(y_train).long())\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val).float().permute(0, 3, 1, 2), torch.from_numpy(y_val).long())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 40\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    val_loss, val_accuracy = evaluate(model, device, val_loader, criterion)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    print('Epoch: {:02d}, Train Loss: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.2f}%'.format(\n",
    "        epoch, train_loss, val_loss, val_accuracy))\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4311, Test Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).float().permute(0, 3, 1, 2), torch.from_numpy(y_test).long())\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loss, test_accuracy = evaluate(model, device, test_loader, criterion)\n",
    "\n",
    "print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
